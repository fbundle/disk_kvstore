below is an implementation of paxos algorithm
./pkg/kvstore/store.go
package kvstore

type Txn[K comparable, V any] interface {
	Get(k K) (v V, ok bool)
	Set(k K, v V)
	Del(k K)
}

// Store - threadsafe stable store
type Store[K comparable, V any] interface {
	Update(update func(txn Txn[K, V]) any) any
}

type MemStore[K comparable, V any] interface {
	Store[K, V]
	Keys() []K
}
./pkg/kvstore/barger_store.go
package kvstore

import (
	"encoding/json"
	"errors"
	"github.com/dgraph-io/badger/v4"
	"sync"
)

func NewBargerStore[K comparable, V any](db *badger.DB) Store[K, V] {
	return &badgerStore[K, V]{
		mu: sync.Mutex{},
		db: db,
	}
}

type badgerStore[K comparable, V any] struct {
	mu sync.Mutex
	db *badger.DB
}

type badgerTxn[K comparable, V any] struct {
	txn *badger.Txn
}

func (b *badgerTxn[K, V]) Get(k K) (v V, ok bool) {
	kb, err := json.Marshal(k)
	if err != nil {
		panic(err)
	}
	i, err := b.txn.Get(kb)
	if errors.Is(err, badger.ErrKeyNotFound) {
		return v, false
	}
	if err != nil {
		panic(err)
	}
	err = i.Value(func(val []byte) error {
		return json.Unmarshal(val, &v)
	})
	if err != nil {
		panic(err)
	}
	return v, true
}

func (b *badgerTxn[K, V]) Set(k K, v V) {
	kb, err := json.Marshal(k)
	if err != nil {
		panic(err)
	}
	vb, err := json.Marshal(v)
	if err != nil {
		panic(err)
	}
	err = b.txn.Set(kb, vb)
	if err != nil {
		panic(err)
	}
}

func (b *badgerTxn[K, V]) Del(k K) {
	kb, err := json.Marshal(k)
	if err != nil {
		panic(err)
	}
	err = b.txn.Delete(kb)
	if err != nil {
		panic(err)
	}
}

func (b *badgerStore[K, V]) Update(update func(txn Txn[K, V]) any) any {
	b.mu.Lock()
	defer b.mu.Unlock()
	var out any
	_ = b.db.Update(func(txn *badger.Txn) error {
		out = update(&badgerTxn[K, V]{txn: txn})
		return nil
	})
	return out
}

func (b *badgerStore[K, V]) Close() {
	err := b.db.Close()
	if err != nil {
		panic(err)
	}
}
./pkg/kvstore/mem_store.go
package kvstore

import "sync"

func NewMemStore[K comparable, V any]() MemStore[K, V] {
	return &memStore[K, V]{
		mu:    sync.Mutex{},
		store: make(map[K]V),
	}
}

type memStore[K comparable, V any] struct {
	mu    sync.Mutex
	store map[K]V
}

func (m *memStore[K, V]) Update(update func(txn Txn[K, V]) any) any {
	m.mu.Lock()
	defer m.mu.Unlock()
	return update(m)
}

func (m *memStore[K, V]) Keys() (keys []K) {
	keys = make([]K, 0, len(m.store))
	for k := range m.store {
		keys = append(keys, k)
	}
	return keys
}

func (m *memStore[K, V]) Get(k K) (v V, ok bool) {
	v, ok = m.store[k]
	return v, ok
}

func (m *memStore[K, V]) Set(k K, v V) {
	m.store[k] = v
}

func (m *memStore[K, V]) Del(k K) {
	delete(m.store, k)
}
./pkg/rpc/dispatcher.go
package rpc

import (
	"encoding/json"
	"fmt"
	"reflect"
)

type Dispatcher interface {
	Register(name string, h any) Dispatcher
	Handle(input []byte) (output []byte, err error)
}

func NewDispatcher() Dispatcher {
	return &dispatcher{
		handlerMap: make(map[string]handler),
	}
}

type message struct {
	Cmd  string `json:"cmd"`
	Body []byte `json:"body"`
}

type handler struct {
	handlerFunc reflect.Value
	argType     reflect.Type
}

type dispatcher struct {
	handlerMap map[string]handler
}

func (d *dispatcher) Register(name string, h any) Dispatcher {
	handlerFunc := reflect.ValueOf(h)
	handlerFuncType := handlerFunc.Type()
	if handlerFuncType.Kind() != reflect.Func || handlerFuncType.NumIn() != 1 || handlerFuncType.NumOut() != 1 {
		panic("handler must be of form func(*SomeRequest) *SomeResponse")
	}
	argType := handlerFuncType.In(0)
	if argType.Kind() != reflect.Ptr || handlerFuncType.Out(0).Kind() != reflect.Ptr {
		panic("handler arguments and return type must be pointers")
	}
	d.handlerMap[name] = handler{
		handlerFunc: handlerFunc,
		argType:     argType,
	}
	return d
}

func (d *dispatcher) Handle(input []byte) (output []byte, err error) {
	msg := message{}
	if err := json.Unmarshal(input, &msg); err != nil {
		return nil, err
	}

	h, ok := d.handlerMap[msg.Cmd]
	if !ok {
		return nil, fmt.Errorf("command not found")
	}

	argPtr := reflect.New(h.argType.Elem()).Interface()
	if err := json.Unmarshal(msg.Body, argPtr); err != nil {
		return nil, err
	}

	out := h.handlerFunc.Call([]reflect.Value{reflect.ValueOf(argPtr)})[0].Interface()

	output, err = json.Marshal(out)
	if err != nil {
		return nil, err
	}
	return output, nil
}
./pkg/rpc/rpc.go
package rpc

import (
	"encoding/json"
)

type TransportFunc func([]byte) ([]byte, error)

func zeroPtr[T any]() *T {
	var v T
	return &v
}

func RPC[Req any, Res any](transport TransportFunc, name string, req *Req) (res *Res, err error) {
	body, err := json.Marshal(req)
	if err != nil {
		return nil, err
	}
	msg := message{
		Cmd:  name,
		Body: body,
	}
	b, err := json.Marshal(msg)
	if err != nil {
		return nil, err
	}
	b, err = transport(b)
	if err != nil {
		return nil, err
	}

	res = zeroPtr[Res]()
	if err := json.Unmarshal(b, res); err != nil {
		return nil, err
	}
	return res, nil
}
./pkg/rpc/tcp_server.go
package rpc

import (
	"fmt"
	"net"
	"os"
	"sync"
	"time"

	"github.com/khanh101/paxos/pkg/crypt"
)

const (
	TCP_TIMEOUT = 10 * time.Second
	AES_KEY_ENV = "AES_KEY"
)

type TCPServer interface {
	Handle(input []byte) (output []byte, err error)
	ListenAndServe() error
	Register(name string, h any) TCPServer
	Close() error
}

func getKey() crypt.Key {
	keyStr := os.Getenv(AES_KEY_ENV)
	key := crypt.NewKey(keyStr)
	return key
}

func TCPTransport(addr string) TransportFunc {
	key := getKey()

	return func(b []byte) ([]byte, error) {

		conn, err := net.Dial("tcp", addr)
		if err != nil {
			fmt.Println(err)
			return nil, err
		}
		defer conn.Close()

		err = conn.SetDeadline(time.Now().Add(TCP_TIMEOUT))
		if err != nil {
			fmt.Println(err)
			return nil, err
		}

		err = key.EncryptToWriter(b, conn)
		if err != nil {
			fmt.Println(err)
			return nil, err
		}

		b, err = key.DecryptFromReader(conn)
		if err != nil {
			fmt.Println(err)
			return nil, err
		}

		return b, nil
	}
}

type tcpServer struct {
	mu         sync.Mutex
	dispatcher Dispatcher
	listener   net.Listener
	key        crypt.Key
}

func NewTCPServer(bindAddr string) (TCPServer, error) {
	listener, err := net.Listen("tcp", bindAddr)
	if err != nil {
		return nil, err
	}
	return &tcpServer{
		mu:         sync.Mutex{},
		dispatcher: NewDispatcher(),
		listener:   listener,
		key:        getKey(),
	}, nil
}

func (s *tcpServer) Close() error {
	return s.listener.Close()
}

func (s *tcpServer) Handle(input []byte) (output []byte, err error) {
	return s.dispatcher.Handle(input)
}

func (s *tcpServer) Register(name string, h any) TCPServer {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.dispatcher.Register(name, h)
	return s
}

func (s *tcpServer) handleConn(conn net.Conn) {
	key := s.key
	defer conn.Close()
	err := conn.SetDeadline(time.Now().Add(TCP_TIMEOUT))
	if err != nil {
		fmt.Println(err)
		return
	}

	b, err := key.DecryptFromReader(conn)
	if err != nil {
		fmt.Println(err)
		return
	}

	{
		s.mu.Lock()
		defer s.mu.Unlock()
		b, err = s.dispatcher.Handle(b)
		if err != nil {
			fmt.Println(err)
			return
		}
	}

	err = key.EncryptToWriter(b, conn)
	if err != nil {
		fmt.Println(err)
		return
	}
}

func (s *tcpServer) ListenAndServe() error {
	for {
		conn, err := s.listener.Accept()
		if err != nil {
			return err
		}
		go s.handleConn(conn)
	}
}
./pkg/dist_kvstore/util.go
package dist_kvstore

import "fmt"

func combineErrors(errs ...error) error {
	var errorList []error

	for _, err := range errs {
		if err == nil {
			continue
		}
		errorList = append(errorList, err)
	}
	if len(errorList) == 0 {
		return nil
	}
	return fmt.Errorf("%v", errorList)
}
./pkg/dist_kvstore/state_machine.go
package dist_kvstore

import (
	"github.com/google/uuid"
	"github.com/khanh101/paxos/pkg/kvstore"
	"github.com/khanh101/paxos/pkg/paxos"
)

type Entry struct {
	Key string `json:"key"`
	Val string `json:"val"`
	Ver uint64 `json:"ver"`
}

type Cmd struct {
	Uuid    uuid.UUID `json:"uuid"`
	Entries []Entry   `json:"entries"`
}

func makeCmd(entries []Entry) Cmd {
	return Cmd{
		Uuid:    uuid.New(),
		Entries: entries,
	}
}

func (cmd Cmd) Equal(other Cmd) bool {
	return cmd.Uuid == other.Uuid
}

type stateMachine struct {
	store kvstore.MemStore[string, Entry]
}

func newStateMachine() *stateMachine {
	return &stateMachine{
		store: kvstore.NewMemStore[string, Entry](),
	}
}

func (sm *stateMachine) Get(key string) Entry {
	return sm.store.Update(func(txn kvstore.Txn[string, Entry]) any {
		return getDefaultEntry(txn, key)
	}).(Entry)
}

func (sm *stateMachine) Keys() []string {
	return sm.store.Update(func(txn kvstore.Txn[string, Entry]) any {
		return sm.store.Keys()
	}).([]string)
}

func (sm *stateMachine) Apply(logId paxos.LogId, cmd Cmd) {
	sm.store.Update(func(txn kvstore.Txn[string, Entry]) any {
		for _, entry := range cmd.Entries {
			oldEntry := getDefaultEntry(txn, entry.Key)
			if entry.Ver <= oldEntry.Ver {
				continue // ignore update
			}
			if len(entry.Val) == 0 {
				txn.Del(entry.Key)
			} else {
				txn.Set(entry.Key, entry)
			}
		}
		return nil
	})
}
./pkg/dist_kvstore/http.go
package dist_kvstore

import (
	"encoding/json"
	"io"
	"net/http"
	"strings"
)

type versionedValue struct {
	Val string `json:"val"`
	Ver uint64 `json:"ver"`
}

func HttpHandle(ds Store) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		if !strings.HasPrefix(r.URL.Path, "/kvstore/") {
			http.NotFound(w, r)
			return
		}
		defer r.Body.Close()

		key, _ := strings.CutPrefix(r.URL.Path, "/kvstore/")
		if len(key) == 0 {
			b, err := json.Marshal(ds.Keys())
			if err != nil {
				http.Error(w, err.Error(), http.StatusInternalServerError)
			}
			_, err = w.Write(b)
			if err != nil {
				http.Error(w, err.Error(), http.StatusInternalServerError)
			}
			return
		}
		switch r.Method {
		case http.MethodGet:
			entry := ds.Get(key)
			b, err := json.Marshal(entry)
			if err != nil {
				http.Error(w, err.Error(), http.StatusInternalServerError)
				return
			}
			_, err = w.Write(b)
			if err != nil {
				http.Error(w, err.Error(), http.StatusInternalServerError)
				return
			}
		case http.MethodPost, http.MethodPut:
			body, err := io.ReadAll(r.Body)
			if err != nil {
				http.Error(w, err.Error(), http.StatusBadRequest)
				return
			}
			v := versionedValue{}
			err = json.Unmarshal(body, &v)
			if err != nil {
				http.Error(w, err.Error(), http.StatusBadRequest)
				return
			}
			cmd := makeCmd([]Entry{
				{
					Key: key,
					Val: v.Val,
					Ver: v.Ver,
				},
			})

			ds.Set(cmd)
			w.WriteHeader(http.StatusOK)
		default:
			http.Error(w, "method must be GET POST PUT", http.StatusBadRequest)
		}

	}
}
./pkg/dist_kvstore/kvstore.go
package dist_kvstore

import (
	"context"
	"math/rand"
	"sync"
	"time"

	"github.com/dgraph-io/badger/v4"
	"github.com/khanh101/paxos/pkg/kvstore"
	"github.com/khanh101/paxos/pkg/paxos"
	"github.com/khanh101/paxos/pkg/rpc"
)

const (
	BACKOFF_MIN_TIME = 10 * time.Millisecond
	BACKOFF_MAX_TIME = 1000 * time.Millisecond
	UPDATE_INTERVAL  = 100 * time.Millisecond
)

type Store interface {
	Close() error
	ListenAndServeRPC() error
	Get(key string) Entry
	Set(Cmd)
	Keys() []string
}

func makeHandlerFunc[Req any, Res any](acceptor paxos.Acceptor[Cmd]) func(*Req) *Res {
	return func(req *Req) *Res {
		res := acceptor.HandleRPC(req)
		if res == nil {
			return nil
		}
		return res.(*Res)
	}
}

type store struct {
	id           paxos.ProposerId
	peerAddrList []string
	db           *badger.DB
	memStore     *stateMachine
	acceptor     paxos.Acceptor[Cmd]
	server       rpc.TCPServer
	rpcList      []paxos.RPC
	writeMu      sync.Mutex
	updateCtx    context.Context
	updateCancel context.CancelFunc
}

func getDefaultEntry(txn kvstore.Txn[string, Entry], key string) Entry {
	entry, ok := txn.Get(key)
	if !ok {
		return Entry{
			Key: key,
			Val: "",
			Ver: 0,
		}
	}
	return entry
}

func NewDistStore(id int, badgerPath string, peerAddrList []string) (Store, error) {
	bindAddr := peerAddrList[id]
	db, err := badger.Open(badger.DefaultOptions(badgerPath))
	if err != nil {
		return nil, err
	}
	acceptor := paxos.NewAcceptor(kvstore.NewBargerStore[paxos.LogId, paxos.Promise[Cmd]](db))
	memStore := newStateMachine()
	acceptor.Subscribe(0, memStore.Apply)

	server, err := rpc.NewTCPServer(bindAddr)
	if err != nil {
		return nil, err
	}
	server = server.
		Register("prepare", makeHandlerFunc[paxos.PrepareRequest, paxos.PrepareResponse[Cmd]](acceptor)).
		Register("accept", makeHandlerFunc[paxos.AcceptRequest[Cmd], paxos.AcceptResponse[Cmd]](acceptor)).
		Register("commit", makeHandlerFunc[paxos.CommitRequest[Cmd], paxos.CommitResponse](acceptor)).
		Register("poll", makeHandlerFunc[paxos.PollRequest, paxos.PollResponse[Cmd]](acceptor))

	rpcList := make([]paxos.RPC, len(peerAddrList))
	for i := range peerAddrList {
		i := i
		if i == id {
			rpcList[i] = func(req paxos.Request, resCh chan<- paxos.Response) {
				resCh <- acceptor.HandleRPC(req)
			}
		} else {
			rpcList[i] = func(req paxos.Request, resCh chan<- paxos.Response) {
				transport := rpc.TCPTransport(peerAddrList[i])
				res, err := func() (paxos.Response, error) {
					switch req.(type) {
					case *paxos.PrepareRequest:
						return rpc.RPC[paxos.PrepareRequest, paxos.PrepareResponse[Cmd]](transport, "prepare", req.(*paxos.PrepareRequest))
					case *paxos.AcceptRequest[Cmd]:
						return rpc.RPC[paxos.AcceptRequest[Cmd], paxos.AcceptResponse[Cmd]](transport, "accept", req.(*paxos.AcceptRequest[Cmd]))
					case *paxos.CommitRequest[Cmd]:
						return rpc.RPC[paxos.CommitRequest[Cmd], paxos.CommitResponse](transport, "commit", req.(*paxos.CommitRequest[Cmd]))
					case *paxos.PollRequest:
						return rpc.RPC[paxos.PollRequest, paxos.PollResponse[Cmd]](transport, "poll", req.(*paxos.PollRequest))
					default:
						return nil, nil
					}
				}()
				if err != nil {
					res = nil
				}
				resCh <- res
			}
		}
	}

	updateCtx, updateCancel := context.WithCancel(context.Background())
	return &store{
		id:           paxos.ProposerId(id),
		peerAddrList: peerAddrList,
		db:           db,
		memStore:     memStore,
		acceptor:     acceptor,
		server:       server,
		rpcList:      rpcList,
		writeMu:      sync.Mutex{},
		updateCtx:    updateCtx,
		updateCancel: updateCancel,
	}, nil
}

func (ds *store) Close() error {
	ds.updateCancel()
	err1 := ds.db.Close()
	err2 := ds.server.Close()
	return combineErrors(err1, err2)
}

func (ds *store) ListenAndServeRPC() error {
	go func() {
		ticker := time.NewTicker(UPDATE_INTERVAL)
		defer ticker.Stop()
		for {
			select {
			case <-ds.updateCtx.Done():
				return
			case <-ticker.C:
				paxos.Update(ds.acceptor, ds.rpcList)
			}
		}

	}()
	return ds.server.ListenAndServe()
}

func (ds *store) Set(cmd Cmd) {
	ds.writeMu.Lock()
	defer ds.writeMu.Unlock()
	wait := BACKOFF_MIN_TIME
	backoff := func() {
		time.Sleep(time.Duration(rand.Intn(int(wait))))
		wait *= 2
		if wait > BACKOFF_MAX_TIME {
			wait = BACKOFF_MAX_TIME
		}
	}
	for {
		logId := ds.acceptor.Next()
		value, ok := paxos.Write(ds.acceptor, ds.id, logId, cmd, ds.rpcList)
		if ok && value.Equal(cmd) {
			break
		}
		backoff()
	}
}

func (ds *store) Get(key string) Entry {
	return ds.memStore.Get(key)
}

func (ds *store) Keys() []string {
	return ds.memStore.Keys()
}
./pkg/paxos/message.go
package paxos

type Request interface {
}

type Response interface {
}
type PrepareRequest struct {
	LogId    LogId    `json:"log_id"`
	Proposal Proposal `json:"proposal"`
}

type PrepareResponse[T any] struct {
	Promise Promise[T] `json:"promise"`
	Ok      bool       `json:"ok"`
}

type AcceptRequest[T any] struct {
	LogId    LogId    `json:"log_id"`
	Proposal Proposal `json:"proposal"`
	Value    T        `json:"value"`
}

type AcceptResponse[T any] struct {
	Promise Promise[T] `json:"promise"`
	Ok      bool       `json:"ok"`
}

type CommitRequest[T any] struct {
	LogId LogId `json:"log_id"`
	Value T     `json:"value"`
}

type CommitResponse struct {
}

type PollRequest struct {
	LogId LogId `json:"log_id"`
}

type PollResponse[T any] struct {
	Proposal Proposal `json:"proposal"`
	Value    *T       `json:"value"`
}
./pkg/paxos/acceptor.go
package paxos

import (
	"sync"

	"github.com/khanh101/paxos/pkg/kvstore"
)

type StateMachine[T any] func(logId LogId, value T)

type Acceptor[T any] interface {
	// GetValue - get value
	GetValue(logId LogId) (val T, ok bool)
	// Next - get smallestUnapplied - used to propose
	Next() LogId
	// HandleRPC - handle RPC requests
	HandleRPC(req Request) (res Response)
	// Subscribe - subscribe a state machine to log
	// smallestUnapplied is the index when state machine will start getting updates
	// it ignores all previous log entries
	Subscribe(smallestUnapplied LogId, sm StateMachine[T]) (cancel func())
}

func NewAcceptor[T any](log kvstore.Store[LogId, Promise[T]]) Acceptor[T] {
	return (&acceptor[T]{
		mu:                sync.Mutex{},
		acceptor:          &simpleAcceptor[T]{log: log},
		smallestUnapplied: 0,
		subsciber:         nil,
	}).applyCommitWithoutLock()
}

// acceptor - paxos acceptor must be persistent
type acceptor[T any] struct {
	mu                sync.Mutex
	acceptor          *simpleAcceptor[T]
	smallestUnapplied LogId
	subsciber         StateMachine[T]
}

func (a *acceptor[T]) applyCommitWithoutLock() *acceptor[T] {
	for {
		proposal, value := a.acceptor.get(a.smallestUnapplied)
		if proposal != COMMITTED {
			break
		}
		if a.subsciber != nil {
			a.subsciber(a.smallestUnapplied, *value)
		}
		a.smallestUnapplied++
	}
	return a
}

func (a *acceptor[T]) Subscribe(smallestUnapplied LogId, sm StateMachine[T]) (cancel func()) {
	a.mu.Lock()
	defer a.mu.Unlock()
	if a.subsciber != nil {
		panic("cannot subscribe twice")
	}
	a.subsciber = sm
	a.smallestUnapplied = smallestUnapplied

	return func() {
		a.mu.Lock()
		defer a.mu.Unlock()
		a.subsciber = nil
	}
}

func (a *acceptor[T]) GetValue(logId LogId) (T, bool) {
	a.mu.Lock()
	defer a.mu.Unlock()
	proposal, value := a.acceptor.get(logId)
	if proposal == COMMITTED {
		return *value, true
	}
	return zero[T](), false
}

func (a *acceptor[T]) Next() LogId {
	a.mu.Lock()
	defer a.mu.Unlock()
	return a.applyCommitWithoutLock().smallestUnapplied
}

func (a *acceptor[T]) HandleRPC(r Request) Response {
	a.mu.Lock()
	defer a.mu.Unlock()
	switch req := r.(type) {
	case *PrepareRequest:
		promise, ok := a.acceptor.prepare(req.LogId, req.Proposal)
		return &PrepareResponse[T]{
			Promise: promise,
			Ok:      ok,
		}
	case *AcceptRequest[T]:
		promise, ok := a.acceptor.accept(req.LogId, req.Proposal, req.Value)
		return &AcceptResponse[T]{
			Promise: promise,
			Ok:      ok,
		}
	case *CommitRequest[T]:
		a.acceptor.commit(req.LogId, req.Value)
		a.applyCommitWithoutLock()
		return nil
	case *PollRequest:
		proposal, value := a.acceptor.get(req.LogId)
		return &PollResponse[T]{
			Proposal: proposal,
			Value:    value,
		}
	default:
		return nil
	}
}
./pkg/paxos/simple_acceptor.go
package paxos

import (
	"github.com/khanh101/paxos/pkg/kvstore"
)

// Proposal - roundId * 4294967296 + nodeId
type Proposal uint64

type LogId uint64

const (
	INITIAL   Proposal = 0
	COMMITTED Proposal = 18446744073709551615
)

// Promise - promise to reject all PREPARE if proposal <= this and all ACCEPT if proposal < this
type Promise[T any] struct {
	Proposal Proposal `json:"proposal"`
	Value    *T       `json:"value"`
}

func zero[T any]() T {
	var v T
	return v
}

type simpleAcceptor[T any] struct {
	log kvstore.Store[LogId, Promise[T]]
}

func getDefaultLogEntry[T any](txn kvstore.Txn[LogId, Promise[T]], logId LogId) (p Promise[T]) {
	v, ok := txn.Get(logId)
	if !ok {
		return Promise[T]{
			Proposal: INITIAL,
			Value:    nil,
		}
	}
	return v
}

func (a *simpleAcceptor[T]) get(logId LogId) (Proposal, *T) {
	promise := a.log.Update(func(txn kvstore.Txn[LogId, Promise[T]]) any {
		return getDefaultLogEntry(txn, logId)
	}).(Promise[T])
	return promise.Proposal, promise.Value
}

func (a *simpleAcceptor[T]) commit(logId LogId, v T) {
	a.log.Update(func(txn kvstore.Txn[LogId, Promise[T]]) any {
		txn.Set(logId, Promise[T]{
			Proposal: COMMITTED,
			Value:    &v,
		})
		return nil
	})
}

func (a *simpleAcceptor[T]) prepare(logId LogId, proposal Proposal) (Promise[T], bool) {
	r := a.log.Update(func(txn kvstore.Txn[LogId, Promise[T]]) any {
		p := getDefaultLogEntry(txn, logId)
		if !(p.Proposal < proposal) {
			return [2]any{p, false}
		}
		txn.Set(logId, Promise[T]{
			Proposal: proposal,
			Value:    p.Value,
		})
		return [2]any{p, true}
	}).([2]any)
	promise, ok := r[0].(Promise[T]), r[1].(bool)
	return promise, ok
}

func (a *simpleAcceptor[T]) accept(logId LogId, proposal Proposal, value T) (Promise[T], bool) {
	r := a.log.Update(func(txn kvstore.Txn[LogId, Promise[T]]) any {
		p := getDefaultLogEntry(txn, logId)
		if !(p.Proposal <= proposal) {
			return [2]any{p, false}
		}
		txn.Set(logId, Promise[T]{
			Proposal: proposal,
			Value:    &value,
		})
		return [2]any{p, true}
	}).([2]any)
	promise, ok := r[0].(Promise[T]), r[1].(bool)
	return promise, ok
}
./pkg/paxos/proposer.go
package paxos

import (
	"math/rand"
	"time"
)

type ProposerId uint64

const (
	PROPOSAL_STEP                  = 4294967296
	BACKOFF_MIN_TIME time.Duration = 10 * time.Millisecond
	BACKOFF_MAX_TIME time.Duration = 1000 * time.Millisecond
)

type Round uint64

func compose(round Round, id ProposerId) Proposal {
	return Proposal(uint64(round)*PROPOSAL_STEP + uint64(id))
}

func decompose(proposal Proposal) (Round, ProposerId) {
	return Round(proposal / PROPOSAL_STEP), ProposerId(proposal % PROPOSAL_STEP)
}

type RPC func(Request, chan<- Response)

func broadcast[Req any, Res any](rpcList []RPC, req Req) []Res {
	ch := make(chan Response, len(rpcList))
	defer close(ch)
	for _, rpc := range rpcList {
		rpc(req, ch)
	}
	resList := make([]Res, 0, len(rpcList))
	for range rpcList {
		res := <-ch
		if res == nil {
			continue
		}
		resList = append(resList, res.(Res))
	}
	return resList
}

// Update - check if there is an update
func Update[T any](a Acceptor[T], rpcList []RPC) Acceptor[T] {
	for {
		logId := a.Next()
		commited := false
		var v T
		for _, res := range broadcast[*PollRequest, *PollResponse[T]](rpcList, &PollRequest{
			LogId: logId,
		}) {
			if res.Proposal == COMMITTED {
				v = *res.Value
				commited = true
				break
			}
		}
		if !commited {
			break
		}
		a.HandleRPC(&CommitRequest[T]{
			LogId: logId,
			Value: v,
		})
	}
	return a
}

// Write - write new value
func Write[T any](a Acceptor[T], id ProposerId, logId LogId, value T, rpcList []RPC) (T, bool) {
	quorum := len(rpcList)/2 + 1
	round := Round(1)

	wait := BACKOFF_MIN_TIME
	// exponential backoff
	backoff := func() {
		round++
		a = Update(a, rpcList)
		time.Sleep(time.Duration(rand.Intn(int(wait))))
		wait *= 2
		if wait > BACKOFF_MAX_TIME {
			wait = BACKOFF_MAX_TIME
		}
	}
	for {
		if _, committed := a.GetValue(logId); committed {
			return zero[T](), false
		}
		// prepare
		proposal := compose(round, id)
		maxValuePtr, ok := func() (*T, bool) {
			maxPromise := Proposal(0)
			maxValuePtr := (*T)(nil)
			okCount := 0
			resList := broadcast[*PrepareRequest, *PrepareResponse[T]](rpcList, &PrepareRequest{
				LogId:    logId,
				Proposal: proposal,
			})
			for _, res := range resList {
				if res.Ok {
					okCount++
					if res.Promise.Value != nil {
						if maxPromise <= res.Promise.Proposal {
							maxPromise = res.Promise.Proposal
							maxValuePtr = res.Promise.Value
						}
					}
				}
			}
			return maxValuePtr, okCount >= quorum
		}()

		if !ok {
			backoff()
			continue
		}
		// accept
		if maxValuePtr == nil {
			maxValuePtr = &value
		}

		ok = func() bool {
			resList := broadcast[*AcceptRequest[T], *AcceptResponse[T]](rpcList, &AcceptRequest[T]{
				LogId:    logId,
				Proposal: proposal,
				Value:    *maxValuePtr,
			})
			okCount := 0
			for _, res := range resList {
				if res.Ok {
					okCount++
				}
			}
			return okCount >= quorum
		}()
		if !ok {
			backoff()
			continue
		}
		// commit
		func() {
			// broadcast commit
			go broadcast[*CommitRequest[T], *CommitResponse](rpcList, &CommitRequest[T]{
				LogId: logId,
				Value: *maxValuePtr,
			})
			// local commit
			a.HandleRPC(&CommitRequest[T]{
				LogId: logId,
				Value: *maxValuePtr,
			})
		}()
		return *maxValuePtr, true
	}
}

func LogCompact[T any](rpcList []RPC) {
	// TODO
	// 1. send request to get smallest logId
	// 2. emit log compaction request
	// 3. T is a sum type of Command CompressedCommand.
	//    compact log entries [0, 1, 2, 3, ...] -> [x, 2, 3, ...]
	//    where x stores CompressedCommand
	// 4. StateMachine applies CompressedCommand is recovering from snapshot
	// 5. initLogId is used to restore the StateMachine

	/*

	 */
	// compressLog[T any](ts ...T) T // type signature for log compression where T is type of value
}
./pkg/crypt/crypt.go
package crypt

import (
	"crypto/aes"
	"crypto/cipher"
	"crypto/rand"
	"crypto/sha256"
	"encoding/binary"
	"fmt"
	"io"
)

func NewKey(s string) Key {
	if len(s) == 0 {
		fmt.Println("WARNING: no key is used")
		return key(nil)
	}
	hash := sha256.Sum256([]byte(s))
	return key(hash[:])
}

type Key interface {
	Encrypt(plaintext []byte) (ciphertext []byte, err error)
	Decrypt(ciphertext []byte) (plaintext []byte, err error)
	EncryptToWriter(plaintext []byte, writer io.Writer) (err error)
	DecryptFromReader(reader io.Reader) (plaintext []byte, err error)
}

type key []byte

func (k key) EncryptToWriter(plaintext []byte, writer io.Writer) (err error) {
	ciphertext, err := k.Encrypt(plaintext)
	if err != nil {
		return err
	}
	n := uint64(len(ciphertext))
	b := make([]byte, 8)
	binary.LittleEndian.PutUint64(b, n)

	_, err = writer.Write(append(b, ciphertext...))
	if err != nil {
		return err
	}
	return nil
}

func (k key) DecryptFromReader(reader io.Reader) (plaintext []byte, err error) {
	b := make([]byte, 8)
	_, err = reader.Read(b)
	if err != nil {
		return nil, err
	}
	n := binary.LittleEndian.Uint64(b)
	ciphertext := make([]byte, n)
	_, err = reader.Read(ciphertext)
	if err != nil {
		return nil, err
	}
	plaintext, err = k.Decrypt(ciphertext)
	if err != nil {
		return nil, err
	}
	return plaintext, nil
}

func (k key) Encrypt(plaintext []byte) (ciphertext []byte, err error) {
	if len(k) == 0 {
		return plaintext, nil
	}

	block, err := aes.NewCipher(k)
	if err != nil {
		return nil, err
	}

	// GCM mode provides authenticated encryption
	aesGCM, err := cipher.NewGCM(block)
	if err != nil {
		return nil, err
	}

	nonce := make([]byte, aesGCM.NonceSize())
	if _, err := io.ReadFull(rand.Reader, nonce); err != nil {
		return nil, err
	}

	// Seal appends the encrypted data to the nonce
	ciphertext = aesGCM.Seal(nonce, nonce, plaintext, nil)
	return ciphertext, nil
}

func (k key) Decrypt(ciphertext []byte) (plaintext []byte, err error) {
	if len(k) == 0 {
		return ciphertext, nil
	}

	block, err := aes.NewCipher(k)
	if err != nil {
		return nil, err
	}

	aesGCM, err := cipher.NewGCM(block)
	if err != nil {
		return nil, err
	}

	nonceSize := aesGCM.NonceSize()
	if len(ciphertext) < nonceSize {
		return nil, fmt.Errorf("ciphertext too short")
	}

	nonce, ciphertext := ciphertext[:nonceSize], ciphertext[nonceSize:]
	plaintext, err = aesGCM.Open(nil, nonce, ciphertext, nil)
	if err != nil {
		return nil, err
	}

	return plaintext, nil
}
do you have any comment on this?
