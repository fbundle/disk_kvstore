below is an implementation of paxos algorithm
./cmd/cat/main.go
package main

import (
	"fmt"
	"github.com/dgraph-io/badger/v4"
	"os"
	"strconv"
)

func main() {
	badgerPath := os.Args[1]
	db, err := badger.Open(badger.DefaultOptions(badgerPath))
	if err != nil {
		panic(err)
	}
	defer db.Close()

	log := make(map[int]string)
	err = db.View(func(txn *badger.Txn) error {
		opts := badger.DefaultIteratorOptions
		it := txn.NewIterator(opts)
		defer it.Close()
		for it.Rewind(); it.Valid(); it.Next() {
			item := it.Item()
			keyBytes := item.Key()
			err := item.Value(func(valBytes []byte) error {
				key, err := strconv.Atoi(string(keyBytes))
				if err != nil {
					fmt.Println(err)
					return nil
				}
				val := string(valBytes)
				log[key] = val
				return nil
			})
			if err != nil {
				return err
			}
		}
		return nil
	})
	if err != nil {
		panic(err)
	}
	key := 0
	for {
		val, ok := log[key]
		if !ok {
			fmt.Printf("stopped with %d keys left\n", len(log))
			break
		}
		fmt.Printf("%d: %s\n", key, val)
		key++
	}
}
./cmd/test/main.go
package main

import (
	"fmt"
	"github.com/khanh101/paxos/kvstore"
	"github.com/khanh101/paxos/paxos"
	"github.com/khanh101/paxos/rpc"
	"math/rand/v2"
	"strings"
	"sync"
)

type stableStore[K comparable, V any] struct {
	store kvstore.Store[K, V]
}

func (s *stableStore[K, V]) Update(update func(txn kvstore.Txn[K, V]) any) any {
	return update(s.store)
}

func makeTestStableStore[K comparable, V any]() kvstore.StableStore[K, V] {
	return &stableStore[K, V]{
		store: kvstore.NewMemStore[K, V](),
	}
}

func testLocal() {
	n := 3

	// make 3 servers
	acceptorList := make([]paxos.Acceptor[string], n)
	for i := 0; i < n; i++ {
		i := i
		acceptorList[i] = paxos.NewAcceptor(makeTestStableStore[paxos.LogId, paxos.Promise[string]]())
	}

	// TODO - make this tcp or http
	// define rpc communication -
	// drop 80% of requests and responses
	// in total, 0.96% of requests don't go through
	dropRate := 0.80
	rpcList := make([]paxos.RPC, n)
	for i := 0; i < n; i++ {
		i := i
		rpcList[i] = func(req paxos.Request, resCh chan<- paxos.Response) {
			go func() {
				if rand.Float64() < dropRate {
					resCh <- nil
					return
				}
				res := acceptorList[i].Handle(req)
				if rand.Float64() < dropRate {
					resCh <- nil
					return
				}
				resCh <- res
			}()
		}
	}

	listenerList := make([][]string, n)
	for i := 0; i < n; i++ {
		i := i
		acceptorList[i].Subscribe(0, func(logId paxos.LogId, value string) {
			fmt.Printf("acceptor %d log_id %d value %v\n", i, logId, value)
			listenerList[i] = append(listenerList[i], fmt.Sprintf("%v", value))
		})
	}

	// send updates at the same time
	wg := sync.WaitGroup{}
	for i := 0; i < n; i++ {
		wg.Add(1)
		go func(i int) {
			defer wg.Done()
			for j := 0; j < 5; j++ {
				v := fmt.Sprintf("value%d", i+3*j)
				for {
					// 1. update the acceptor
					// 2. get a new logId
					// 3. try to write the value to logId
					// 4. if failed, go back to 1
					logId := acceptorList[i].Next()
					ok := paxos.Write(acceptorList[i], paxos.NodeId(i), logId, v, rpcList)
					if ok {
						break
					}
					paxos.Update(acceptorList[i], rpcList)
				}
			}
		}(i)
	}

	wg.Wait()

	// update the servers
	dropRate = 0.0
	for i := 0; i < n; i++ {
		paxos.Update(acceptorList[i], rpcList)
	}
	// check the committed values
	// it should print the same 3 lines
	for i := 0; i < n; i++ {
		fmt.Println(strings.Join(listenerList[i], ""))
	}

	// new subscriber from 13
	for i := 0; i < n; i++ {
		acceptorList[i].Subscribe(13, func(logId paxos.LogId, value string) {
			fmt.Printf("%v", value)
		})
		fmt.Println()
	}

	return
}

func testRPC() {
	type AddReq struct {
		Values []int
	}

	type AddRes struct {
		Sum int
	}

	type SubReq struct {
		A int
		B int
	}

	type SubRes struct {
		Diff int
	}

	d := rpc.NewDispatcher()

	d.Register("add", func(req *AddReq) (res *AddRes) {
		sum := 0
		for _, v := range req.Values {
			sum += v
		}
		return &AddRes{
			Sum: sum,
		}
	}).Register("sub", func(req *SubReq) (res *SubRes) {
		return &SubRes{
			Diff: req.A - req.B,
		}
	})

	localTransport := d.Handle
	{
		res, err := rpc.RPC[AddReq, AddRes](
			localTransport,
			"add",
			&AddReq{Values: []int{1, 2, 3}},
		)
		if err != nil {
			panic(err)
		}
		fmt.Println(res)
	}
	{
		res, err := rpc.RPC[SubReq, SubRes](
			localTransport,
			"sub",
			&SubReq{A: 20, B: 16},
		)
		if err != nil {
			panic(err)
		}
		fmt.Println(res)
	}
}

func testRPCTCP() {
	type AddReq struct {
		Values []int
	}

	type AddRes struct {
		Sum int
	}

	type SubReq struct {
		A int
		B int
	}

	type SubRes struct {
		Diff int
	}

	addr := "localhost:14001"
	s, err := rpc.NewTCPServer(addr)
	if err != nil {
		panic(err)
	}
	defer s.Close()

	s.Register("add", func(req *AddReq) (res *AddRes) {
		sum := 0
		for _, v := range req.Values {
			sum += v
		}
		return &AddRes{
			Sum: sum,
		}
	}).Register("sub", func(req *SubReq) (res *SubRes) {
		return &SubRes{
			Diff: req.A - req.B,
		}
	})

	go s.ListenAndServeRPC()

	transport := rpc.TCPTransport(addr)
	{
		res, err := rpc.RPC[AddReq, AddRes](
			transport,
			"add",
			&AddReq{Values: []int{1, 2, 3}},
		)
		if err != nil {
			panic(err)
		}
		fmt.Println(res)
	}
	{
		res, err := rpc.RPC[SubReq, SubRes](
			transport,
			"sub",
			&SubReq{A: 20, B: 16},
		)
		if err != nil {
			panic(err)
		}
		fmt.Println(res)
	}
}

func main() {
	testRPC()
}
./dist_kvstore/kvstore.go
package dist_kvstore

import (
	"context"
	"github.com/dgraph-io/badger/v4"
	"github.com/khanh101/paxos/kvstore"
	"github.com/khanh101/paxos/paxos"
	"github.com/khanh101/paxos/rpc"
	"sync"
	"time"
)

type Store interface {
	Close() error
	ListenAndServeRPC() error
	Get(key string) (string, bool)
	Next() int
	Set(token int, key string, val string) bool
	Keys() []string
}

func makeHandlerFunc[Req any, Res any](acceptor paxos.Acceptor[command]) func(*Req) *Res {
	return func(req *Req) *Res {
		res := acceptor.Handle(req)
		if res == nil {
			return nil
		}
		return res.(*Res)
	}
}

type command struct {
	Key string `json:"key"`
	Val string `json:"val"`
}
type store struct {
	id           paxos.NodeId
	peerAddrList []string
	db           *badger.DB
	memStore     kvstore.Store[string, string]
	acceptor     paxos.Acceptor[command]
	server       rpc.TCPServer
	rpcList      []paxos.RPC
	writeMu      sync.Mutex
	updateCtx    context.Context
	updateCancel context.CancelFunc
}

func NewDistStore(id int, badgerPath string, peerAddrList []string) (Store, error) {
	bindAddr := peerAddrList[id]
	db, err := badger.Open(badger.DefaultOptions(badgerPath))
	if err != nil {
		return nil, err
	}
	acceptor := paxos.NewAcceptor[command](kvstore.NewBargerStore[paxos.LogId, paxos.Promise[command]](db))
	memStore := kvstore.NewMemStore[string, string]()
	acceptor.Subscribe(0, func(logId paxos.LogId, cmd command) {
		if cmd.Val == "" {
			memStore.Del(cmd.Key)
		} else {
			memStore.Set(cmd.Key, cmd.Val)
		}
	})

	server, err := rpc.NewTCPServer(bindAddr)
	if err != nil {
		return nil, err
	}
	server = server.
		Register("prepare", makeHandlerFunc[paxos.PrepareRequest, paxos.PrepareResponse](acceptor)).
		Register("accept", makeHandlerFunc[paxos.AcceptRequest[command], paxos.AcceptResponse](acceptor)).
		Register("commit", makeHandlerFunc[paxos.CommitRequest[command], paxos.CommitResponse](acceptor)).
		Register("poll", makeHandlerFunc[paxos.PollRequest, paxos.PollResponse[command]](acceptor))

	rpcList := make([]paxos.RPC, len(peerAddrList))
	for i := range peerAddrList {
		i := i
		if i == id {
			rpcList[i] = func(req paxos.Request, resCh chan<- paxos.Response) {
				resCh <- acceptor.Handle(req)
			}
		} else {
			rpcList[i] = func(req paxos.Request, resCh chan<- paxos.Response) {
				transport := rpc.TCPTransport(peerAddrList[i])
				res, err := func() (paxos.Response, error) {
					switch req.(type) {
					case *paxos.PrepareRequest:
						return rpc.RPC[paxos.PrepareRequest, paxos.PrepareResponse](transport, "prepare", req.(*paxos.PrepareRequest))
					case *paxos.AcceptRequest[command]:
						return rpc.RPC[paxos.AcceptRequest[command], paxos.AcceptResponse](transport, "accept", req.(*paxos.AcceptRequest[command]))
					case *paxos.CommitRequest[command]:
						return rpc.RPC[paxos.CommitRequest[command], paxos.CommitResponse](transport, "commit", req.(*paxos.CommitRequest[command]))
					case *paxos.PollRequest:
						return rpc.RPC[paxos.PollRequest, paxos.PollResponse[command]](transport, "poll", req.(*paxos.PollRequest))
					default:
						return nil, nil
					}
				}()
				if err != nil {
					res = nil
				}
				resCh <- res
			}
		}
	}

	updateCtx, updateCancel := context.WithCancel(context.Background())
	return &store{
		id:           paxos.NodeId(id),
		peerAddrList: peerAddrList,
		db:           db,
		memStore:     memStore,
		acceptor:     acceptor,
		server:       server,
		rpcList:      rpcList,
		writeMu:      sync.Mutex{},
		updateCtx:    updateCtx,
		updateCancel: updateCancel,
	}, nil
}

func (ds *store) Close() error {
	ds.updateCancel()
	err1 := ds.db.Close()
	err2 := ds.server.Close()
	return combineErrors(err1, err2)
}

func (ds *store) ListenAndServeRPC() error {
	go func() {
		ticker := time.NewTicker(100 * time.Millisecond)
		defer ticker.Stop()
		for {
			select {
			case <-ds.updateCtx.Done():
				return
			case <-ticker.C:
				paxos.Update(ds.acceptor, ds.rpcList)
			}
		}

	}()
	return ds.server.ListenAndServeRPC()
}

func (ds *store) Next() int {
	ds.writeMu.Lock()
	defer ds.writeMu.Unlock()
	logId := ds.acceptor.Next()
	return int(logId)
}

func (ds *store) Set(token int, key string, val string) bool {
	ds.writeMu.Lock()
	defer ds.writeMu.Unlock()
	logId := paxos.LogId(token)
	ok := paxos.Write(ds.acceptor, ds.id, logId, command{Key: key, Val: val}, ds.rpcList)
	return ok
}

func (ds *store) Get(key string) (string, bool) {
	return ds.memStore.Get(key)
}

func (ds *store) Keys() []string {
	return ds.memStore.Keys()
}
./dist_kvstore/util.go
package dist_kvstore

import "fmt"

func combineErrors(errs ...error) error {
	var errorList []error

	for _, err := range errs {
		if err == nil {
			continue
		}
		errorList = append(errorList, err)
	}
	if len(errorList) == 0 {
		return nil
	}
	return fmt.Errorf("%v", errorList)
}
./dist_kvstore/http.go
package dist_kvstore

import (
	"encoding/json"
	"io"
	"net/http"
	"strconv"
	"strings"
)

func HttpHandle(ds Store) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		if strings.HasPrefix(r.URL.Path, "/kvstore_keys") {
			keys := ds.Keys()
			b, err := json.Marshal(keys)
			if err != nil {
				http.Error(w, err.Error(), http.StatusInternalServerError)
				return
			}
			_, err = w.Write(b)
			if err != nil {
				http.Error(w, err.Error(), http.StatusInternalServerError)
			}
		} else if strings.HasPrefix(r.URL.Path, "/kvstore_next") {
			token := ds.Next()
			tokenStr := strconv.Itoa(token)
			_, err := w.Write([]byte(tokenStr))
			if err != nil {
				http.Error(w, err.Error(), http.StatusInternalServerError)
				return
			}
		} else if strings.HasPrefix(r.URL.Path, "/kvstore/") {
			key, _ := strings.CutPrefix(r.URL.Path, "/kvstore/")
			switch r.Method {
			case http.MethodGet:
				val, ok := ds.Get(key)
				if !ok {
					http.Error(w, "key not found", http.StatusNotFound)
					return
				}
				_, err := w.Write([]byte(val))
				if err != nil {
					http.Error(w, err.Error(), http.StatusInternalServerError)
					return
				}
			case http.MethodPost, http.MethodPut:
				tokenStr := r.URL.Query().Get("token")
				if tokenStr == "" {
					http.Error(w, "token is required", http.StatusBadRequest)
					return
				}
				token, err := strconv.Atoi(tokenStr)
				if err != nil {
					http.Error(w, err.Error(), http.StatusBadRequest)
					return
				}
				body, err := io.ReadAll(r.Body)
				if err != nil {
					http.Error(w, err.Error(), http.StatusBadRequest)
					return
				}
				val := string(body)
				ok := ds.Set(token, key, val)
				if !ok {
					http.Error(w, "token conflict", http.StatusConflict)
					return
				}
				w.WriteHeader(http.StatusOK)
			default:
				http.Error(w, "method must be GET POST PUT", http.StatusBadRequest)
			}
		} else {
			http.NotFound(w, r)
		}
	}
}
./paxos/simple_acceptor.go
package paxos

import (
	"github.com/khanh101/paxos/kvstore"
)

// ProposalNumber - roundId * 4294967296 + nodeId
type ProposalNumber uint64

const (
	INITIAL   ProposalNumber = 0
	COMMITTED ProposalNumber = 18446744073709551615
)

// Promise - promise to reject all PREPARE if proposal <= this and all ACCEPT if proposal < this
type Promise[T any] struct {
	Proposal ProposalNumber `json:"proposal"`
	Value    T              `json:"value"`
}

func zero[T any]() T {
	var v T
	return v
}

type LogId uint64

type simpleAcceptor[T any] struct {
	log kvstore.StableStore[LogId, Promise[T]]
}

func getOrSetLogEntry[T any](txn kvstore.Txn[LogId, Promise[T]], logId LogId) (p Promise[T]) {
	if v, ok := txn.Get(logId); ok {
		return v
	}
	v := Promise[T]{
		Proposal: INITIAL,
		Value:    zero[T](),
	}
	txn.Set(logId, v)
	return v
}

func (a *simpleAcceptor[T]) get(logId LogId) (promise Promise[T]) {
	return a.log.Update(func(txn kvstore.Txn[LogId, Promise[T]]) any {
		return getOrSetLogEntry(txn, logId)
	}).(Promise[T])
}

func (a *simpleAcceptor[T]) commit(logId LogId, v T) {
	a.log.Update(func(txn kvstore.Txn[LogId, Promise[T]]) any {
		txn.Set(logId, Promise[T]{
			Proposal: COMMITTED,
			Value:    v,
		})
		return nil
	})
}

func (a *simpleAcceptor[T]) prepare(logId LogId, proposal ProposalNumber) (proposalOut ProposalNumber, ok bool) {
	r := a.log.Update(func(txn kvstore.Txn[LogId, Promise[T]]) any {
		p := getOrSetLogEntry(txn, logId)
		if p.Proposal == COMMITTED { // reject if committed
			return [2]any{COMMITTED, false}
		}
		if proposal <= p.Proposal { // fulfill promise
			return [2]any{p.Proposal, false}
		}
		// make new promise
		txn.Set(logId, Promise[T]{
			Proposal: proposal,
			Value:    p.Value, // old value
		})
		return [2]any{proposal, true}
	}).([2]any)
	return r[0].(ProposalNumber), r[1].(bool)
}

func (a *simpleAcceptor[T]) accept(logId LogId, proposal ProposalNumber, value T) (proposalOut ProposalNumber, ok bool) {
	r := a.log.Update(func(txn kvstore.Txn[LogId, Promise[T]]) any {
		p := getOrSetLogEntry(txn, logId)
		if p.Proposal == COMMITTED { // reject if committed
			return [2]any{COMMITTED, false}
		}
		if proposal < p.Proposal { // fulfill promise
			return [2]any{p.Proposal, false}
		}
		// make new promise
		txn.Set(logId, Promise[T]{
			Proposal: proposal,
			Value:    value, // new value
		})
		return [2]any{proposal, true}
	}).([2]any)
	return r[0].(ProposalNumber), r[1].(bool)
}
./paxos/acceptor.go
package paxos

import (
	"github.com/khanh101/paxos/kvstore"
	"sync"
)

type Acceptor[T any] interface {
	Get(logId LogId) (val T, ok bool)
	Next() LogId
	Handle(req Request) (res Response)
	Subscribe(init LogId, subscriber func(logId LogId, value T)) (cancel func())
}

func NewAcceptor[T any](log kvstore.StableStore[LogId, Promise[T]]) Acceptor[T] {
	return (&acceptor[T]{
		mu: sync.Mutex{},
		acceptor: &simpleAcceptor[T]{
			log: log,
		},
		smallestUnapplied: 0,
		subscriberCount:   0,
		subscriberMap:     make(map[uint64]func(logId LogId, value T)),
	}).updateLocalCommitWithoutLock()
}

// acceptor - paxos acceptor must be persistent
type acceptor[T any] struct {
	mu                sync.Mutex
	acceptor          *simpleAcceptor[T]
	smallestUnapplied LogId
	subscriberCount   uint64
	subscriberMap     map[uint64]func(logId LogId, value T)
}

func (a *acceptor[T]) updateLocalCommitWithoutLock() *acceptor[T] {
	for {
		promise := a.acceptor.get(a.smallestUnapplied)
		if promise.Proposal != COMMITTED {
			break
		}
		for _, subscriber := range a.subscriberMap {
			subscriber(a.smallestUnapplied, promise.Value)
		}
		a.smallestUnapplied++
	}
	return a
}

func (a *acceptor[T]) Subscribe(init LogId, subscriber func(logId LogId, value T)) (cancel func()) {
	a.mu.Lock()
	defer a.mu.Unlock()
	if a.smallestUnapplied < init {
		panic("subscribe from a future log_id")
	}
	for logId := init; logId < a.smallestUnapplied; logId++ {
		subscriber(logId, a.acceptor.get(logId).Value)
	}
	count := a.subscriberCount
	a.subscriberCount++
	a.subscriberMap[count] = subscriber
	return func() {
		a.mu.Lock()
		defer a.mu.Unlock()
		delete(a.subscriberMap, count)
	}
}

func (a *acceptor[T]) Get(logId LogId) (T, bool) {
	a.mu.Lock()
	defer a.mu.Unlock()
	promise := a.acceptor.get(logId)
	return promise.Value, promise.Proposal == COMMITTED
}

func (a *acceptor[T]) Next() LogId {
	a.mu.Lock()
	defer a.mu.Unlock()
	return a.updateLocalCommitWithoutLock().smallestUnapplied
}
func (a *acceptor[T]) Handle(r Request) Response {
	a.mu.Lock()
	defer a.mu.Unlock()
	switch req := r.(type) {
	case *PrepareRequest:
		proposal, ok := a.acceptor.prepare(req.LogId, req.Proposal)
		return &PrepareResponse{
			Proposal: proposal,
			Ok:       ok,
		}
	case *AcceptRequest[T]:
		proposal, ok := a.acceptor.accept(req.LogId, req.Proposal, req.Value)
		return &AcceptResponse{
			Proposal: proposal,
			Ok:       ok,
		}
	case *CommitRequest[T]:
		a.acceptor.commit(req.LogId, req.Value)
		a.updateLocalCommitWithoutLock()
		return nil
	case *PollRequest:
		promise := a.acceptor.get(req.LogId)
		return &PollResponse[T]{
			Promise: promise,
		}
	default:
		return nil
	}
}
./paxos/message.go
package paxos

type Request interface {
}

type Response interface {
}
type PrepareRequest struct {
	LogId    LogId          `json:"log_id"`
	Proposal ProposalNumber `json:"proposal"`
}

type PrepareResponse struct {
	Proposal ProposalNumber `json:"proposal"`
	Ok       bool           `json:"ok"`
}

type AcceptRequest[T any] struct {
	LogId    LogId          `json:"log_id"`
	Proposal ProposalNumber `json:"proposal"`
	Value    T              `json:"value"`
}

type AcceptResponse struct {
	Proposal ProposalNumber `json:"proposal"`
	Ok       bool           `json:"ok"`
}

type CommitRequest[T any] struct {
	LogId LogId `json:"log_id"`
	Value T     `json:"value"`
}

type CommitResponse struct {
}

type PollRequest struct {
	LogId LogId `json:"log_id"`
}

type PollResponse[T any] struct {
	Promise Promise[T] `json:"promise"`
}
./paxos/proposer.go
package paxos

import "time"

type NodeId uint64

const (
	PROPOSAL_STEP    ProposalNumber = 4294967296
	BACKOFF_MIN_TIME                = 10 * time.Millisecond
)

func decompose(proposal ProposalNumber) (uint64, NodeId) {
	return uint64(proposal / PROPOSAL_STEP), NodeId(proposal % PROPOSAL_STEP)
}
func compose(round uint64, nodeId NodeId) ProposalNumber {
	return PROPOSAL_STEP*ProposalNumber(round) + ProposalNumber(nodeId)
}

func quorum(n int) int {
	return n/2 + 1
}

type RPC func(Request, chan<- Response)

func broadcast[Req any, Res any](rpcList []RPC, req Req) []Res {
	ch := make(chan Response, len(rpcList))
	defer close(ch)
	for _, rpc := range rpcList {
		rpc(req, ch)
	}
	resList := make([]Res, 0, len(rpcList))
	for range rpcList {
		res := <-ch
		if res == nil {
			continue
		}
		resList = append(resList, res.(Res))
	}
	return resList
}

// Update - check if there is an update
func Update[T any](a Acceptor[T], rpcList []RPC) Acceptor[T] {
	for {
		logId := a.Next()
		commited := false
		var v T
		for _, res := range broadcast[*PollRequest, *PollResponse[T]](rpcList, &PollRequest{
			LogId: logId,
		}) {
			if res.Promise.Proposal == COMMITTED {
				v = res.Promise.Value
				commited = true
				break
			}
		}
		if !commited {
			break
		}
		a.Handle(&CommitRequest[T]{
			LogId: logId,
			Value: v,
		})
	}
	return a
}

// Write - write new value
func Write[T any](a Acceptor[T], id NodeId, logId LogId, value T, rpcList []RPC) bool {
	n := len(rpcList)
	proposal := compose(0, id)
	wait := BACKOFF_MIN_TIME
	// exponential backoff
	backoff := func() {
		a = Update(a, rpcList)
		time.Sleep(wait)
		wait *= 2
	}
	for {
		if _, committed := a.Get(logId); committed {
			return false
		}
		// prepare
		{
			resList := broadcast[*PrepareRequest, *PrepareResponse](rpcList, &PrepareRequest{
				LogId:    logId,
				Proposal: proposal,
			})
			okCount := 0
			for _, res := range resList {
				if res.Ok {
					okCount++
				}
			}
			if okCount < quorum(n) {
				// update proposal
				maxRound := uint64(0)
				for _, res := range resList {
					round, _ := decompose(res.Proposal)
					if maxRound < round {
						maxRound = round
					}
				}
				proposal = compose(maxRound+1, id)
				backoff()
				continue
			}
		}
		// accept
		{
			resList := broadcast[*AcceptRequest[T], *AcceptResponse](rpcList, &AcceptRequest[T]{
				LogId:    logId,
				Proposal: proposal,
				Value:    value,
			})
			okCount := 0
			for _, res := range resList {
				if res.Ok {
					okCount++
				}
			}
			if okCount < quorum(n) {
				// update proposal
				maxRound := uint64(0)
				for _, res := range resList {
					round, _ := decompose(res.Proposal)
					if maxRound < round {
						maxRound = round
					}
				}
				proposal = compose(maxRound+1, id)
				backoff()
				continue
			}
		}
		// commit
		{
			// broadcast commit
			go broadcast[*CommitRequest[T], *CommitResponse](rpcList, &CommitRequest[T]{
				LogId: logId,
				Value: value,
			})
			// local commit
			a.Handle(&CommitRequest[T]{
				LogId: logId,
				Value: value,
			})
		}
		return true
	}
}
./kvstore/mem_store.go
package kvstore

import "sync"

func NewMemStore[K comparable, V any]() Store[K, V] {
	return &memStore[K, V]{
		mu:    sync.RWMutex{},
		store: make(map[K]V),
	}
}

type memStore[K comparable, V any] struct {
	mu    sync.RWMutex
	store map[K]V
}

func (m *memStore[K, V]) Keys() (keys []K) {
	m.mu.RLock()
	defer m.mu.RUnlock()
	keys = make([]K, 0, len(m.store))
	for k := range m.store {
		keys = append(keys, k)
	}
	return keys
}

func (m *memStore[K, V]) Get(k K) (v V, ok bool) {
	m.mu.RLock()
	defer m.mu.RUnlock()
	v, ok = m.store[k]
	return v, ok
}

func (m *memStore[K, V]) Set(k K, v V) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.store[k] = v
}

func (m *memStore[K, V]) Del(k K) {
	m.mu.Lock()
	defer m.mu.Unlock()
	delete(m.store, k)
}
./kvstore/store.go
package kvstore

type Txn[K comparable, V any] interface {
	Get(k K) (v V, ok bool)
	Set(k K, v V)
	Del(k K)
}

// StableStore - threadsafe stable store
type StableStore[K comparable, V any] interface {
	Update(update func(txn Txn[K, V]) any) any
}

// Store - threadsafe memory store
type Store[K comparable, V any] interface {
	Txn[K, V]
	Keys() (keys []K)
}
./kvstore/barger_store.go
package kvstore

import (
	"encoding/json"
	"errors"
	"github.com/dgraph-io/badger/v4"
	"sync"
)

func NewBargerStore[K comparable, V any](db *badger.DB) StableStore[K, V] {
	return &badgerStore[K, V]{
		mu: sync.Mutex{},
		db: db,
	}
}

type badgerStore[K comparable, V any] struct {
	mu sync.Mutex
	db *badger.DB
}

type badgerTxn[K comparable, V any] struct {
	txn *badger.Txn
}

func (b *badgerTxn[K, V]) Get(k K) (v V, ok bool) {
	kb, err := json.Marshal(k)
	if err != nil {
		panic(err)
	}
	i, err := b.txn.Get(kb)
	if errors.Is(err, badger.ErrKeyNotFound) {
		return v, false
	}
	if err != nil {
		panic(err)
	}
	err = i.Value(func(val []byte) error {
		return json.Unmarshal(val, &v)
	})
	if err != nil {
		panic(err)
	}
	return v, true
}

func (b *badgerTxn[K, V]) Set(k K, v V) {
	kb, err := json.Marshal(k)
	if err != nil {
		panic(err)
	}
	vb, err := json.Marshal(v)
	if err != nil {
		panic(err)
	}
	err = b.txn.Set(kb, vb)
	if err != nil {
		panic(err)
	}
}

func (b *badgerTxn[K, V]) Del(k K) {
	kb, err := json.Marshal(k)
	if err != nil {
		panic(err)
	}
	err = b.txn.Delete(kb)
	if err != nil {
		panic(err)
	}
}

func (b *badgerStore[K, V]) Update(update func(txn Txn[K, V]) any) any {
	b.mu.Lock()
	defer b.mu.Unlock()
	var out any
	_ = b.db.Update(func(txn *badger.Txn) error {
		out = update(&badgerTxn[K, V]{txn: txn})
		return nil
	})
	return out
}

func (b *badgerStore[K, V]) Close() {
	err := b.db.Close()
	if err != nil {
		panic(err)
	}
}
./rpc/dispatcher.go
package rpc

import (
	"encoding/json"
	"fmt"
	"reflect"
)

type Dispatcher interface {
	Register(name string, h any) Dispatcher
	Handle(input []byte) (output []byte, err error)
}

func NewDispatcher() Dispatcher {
	return &dispatcher{
		handlerMap: make(map[string]handler),
	}
}

type message struct {
	Cmd  string `json:"cmd"`
	Body []byte `json:"body"`
}

type handler struct {
	handlerFunc reflect.Value
	argType     reflect.Type
}

type dispatcher struct {
	handlerMap map[string]handler
}

func (d *dispatcher) Register(name string, h any) Dispatcher {
	handlerFunc := reflect.ValueOf(h)
	handlerFuncType := handlerFunc.Type()
	if handlerFuncType.Kind() != reflect.Func || handlerFuncType.NumIn() != 1 || handlerFuncType.NumOut() != 1 {
		panic("handler must be of form func(*SomeRequest) *SomeResponse")
	}
	argType := handlerFuncType.In(0)
	if argType.Kind() != reflect.Ptr || handlerFuncType.Out(0).Kind() != reflect.Ptr {
		panic("handler arguments and return type must be pointers")
	}
	d.handlerMap[name] = handler{
		handlerFunc: handlerFunc,
		argType:     argType,
	}
	return d
}

func (d *dispatcher) Handle(input []byte) (output []byte, err error) {
	msg := message{}
	if err := json.Unmarshal(input, &msg); err != nil {
		return nil, err
	}

	h, ok := d.handlerMap[msg.Cmd]
	if !ok {
		return nil, fmt.Errorf("command not found")
	}

	argPtr := reflect.New(h.argType.Elem()).Interface()
	if err := json.Unmarshal(msg.Body, argPtr); err != nil {
		return nil, err
	}

	out := h.handlerFunc.Call([]reflect.Value{reflect.ValueOf(argPtr)})[0].Interface()

	output, err = json.Marshal(out)
	if err != nil {
		return nil, err
	}
	return output, nil
}
./rpc/tcp_server.go
package rpc

import (
	"bufio"
	"fmt"
	"io"
	"net"
	"sync"
	"time"
)

const (
	TCP_TIMEOUT = 10 * time.Second
)

type TCPServer interface {
	Handle(input []byte) (output []byte, err error)
	ListenAndServeRPC() error
	Register(name string, h any) TCPServer
	Close() error
}

func TCPTransport(addr string) TransportFunc {
	return func(input []byte) (output []byte, err error) {
		conn, err := net.Dial("tcp", addr)
		if err != nil {
			return nil, err
		}
		defer conn.Close()

		err = conn.SetDeadline(time.Now().Add(TCP_TIMEOUT))
		if err != nil {
			return
		}

		conn.Write(input)
		conn.Write([]byte("\n")) // '\n' notifies end of input
		output, err = io.ReadAll(conn)
		return output, err
	}
}

type tcpServer struct {
	mu         sync.Mutex
	dispatcher Dispatcher
	listener   net.Listener
}

func NewTCPServer(bindAddr string) (TCPServer, error) {
	listener, err := net.Listen("tcp", bindAddr)
	if err != nil {
		return nil, err
	}
	return &tcpServer{
		mu:         sync.Mutex{},
		dispatcher: NewDispatcher(),
		listener:   listener,
	}, nil
}

func (s *tcpServer) Close() error {
	return s.listener.Close()
}

func (s *tcpServer) Handle(input []byte) (output []byte, err error) {
	return s.dispatcher.Handle(input)
}

func (s *tcpServer) Register(name string, h any) TCPServer {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.dispatcher.Register(name, h)
	return s
}

func (s *tcpServer) handleConn(conn net.Conn) {
	defer conn.Close()
	err := conn.SetDeadline(time.Now().Add(TCP_TIMEOUT))
	if err != nil {
		return
	}

	msg, err := bufio.NewReader(conn).ReadString('\n') // read until '\n'
	if err != nil {
		return
	}
	b := []byte(msg)
	{
		s.mu.Lock()
		defer s.mu.Unlock()
		b, err = s.dispatcher.Handle(b)
	}
	if err != nil {
		fmt.Println(err)
		return
	}
	_, err = conn.Write(b)
	if err != nil {
		return
	}
}

func (s *tcpServer) ListenAndServeRPC() error {
	for {
		conn, err := s.listener.Accept()
		if err != nil {
			return err
		}
		go s.handleConn(conn)
	}
}
./rpc/rpc.go
package rpc

import (
	"encoding/json"
)

type TransportFunc func([]byte) ([]byte, error)

func zeroPtr[T any]() *T {
	var v T
	return &v
}

func RPC[Req any, Res any](transport TransportFunc, name string, req *Req) (res *Res, err error) {
	body, err := json.Marshal(req)
	if err != nil {
		return nil, err
	}
	msg := message{
		Cmd:  name,
		Body: body,
	}
	b, err := json.Marshal(msg)
	if err != nil {
		return nil, err
	}
	b, err = transport(b)
	if err != nil {
		return nil, err
	}

	res = zeroPtr[Res]()
	if err := json.Unmarshal(b, res); err != nil {
		return nil, err
	}
	return res, nil
}
./main.go
package main

import (
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	"strconv"
	"time"

	"github.com/khanh101/paxos/dist_kvstore"
)

type Config struct {
	Badger string `json:"badger"`
	RPC    string `json:"rpc"`
	Store  string `json:"store"`
}
type ConfigList []Config

func main() {
	b, err := os.ReadFile(os.Args[1])
	if err != nil {
		panic(err)
	}
	var cl ConfigList
	err = json.Unmarshal(b, &cl)
	if err != nil {
		panic(err)
	}

	id, err := strconv.Atoi(os.Args[2])
	if err != nil {
		panic(err)
	}

	badgerDBPath := cl[id].Badger
	peerAddrList := make([]string, len(cl))
	for i, c := range cl {
		peerAddrList[i] = c.RPC
	}
	ds, err := dist_kvstore.NewDistStore(id, badgerDBPath, peerAddrList)
	if err != nil {
		panic(err)
	}
	defer ds.Close()
	go ds.ListenAndServeRPC()
	time.Sleep(time.Second)

	// http server
	hs := &http.Server{
		Addr:    cl[id].Store,
		Handler: dist_kvstore.HttpHandle(ds),
	}
	fmt.Println("http server listening on", cl[id].Store)
	err = hs.ListenAndServe()
	if err != nil {
		panic(err)
	}
	return
}
./client.py
import json
import time
from typing import Iterator

import requests


def make_request(method: str, addr: str, path: str, **kwargs) -> requests.Response:
    res = requests.request(method, f"{addr}/{path}", **kwargs)
    res.raise_for_status()
    return res

class KVStore:
    def __init__(self, addr: str = "http://localhost:4000"):
        self.addr = addr

    def get(self, key: str) -> str:
        return make_request("GET", self.addr, f"kvstore/{key}").text

    def next_token(self) -> int:
        return int(make_request("GET", self.addr, "kvstore_next").text)

    def set(self, token: int, key: str, value: str = ""):
        return make_request("PUT", self.addr, f"kvstore/{key}?token={token}", data=value)

    def keys(self) -> list[str]:
        return json.loads(make_request("GET", self.addr, "kvstore_keys").text)

class KVStoreDict:
    def __init__(self, addr: str = "http://localhost:4000"):
        self.kvstore = KVStore(addr)

    def __getitem__(self, key: str) -> str:
        return self.kvstore.get(key)

    def get(self, key: str, default: str = "") -> str:
        try:
            return self.__getitem__(key)
        except requests.exceptions.HTTPError as err:
            if err.response.status_code == 404: # not found
                return default
            raise err

    def __setitem__(self, key: str, value: str) -> int:
        wait = 0.001
        while True:
            try:
                token = self.kvstore.next_token()
                self.kvstore.set(token, key, value)
                return token
            except requests.exceptions.HTTPError as err:
                if err.response.status_code != 409: # not conflict
                    raise err

            time.sleep(wait)
            wait *= 2

    def __delitem__(self, key: str):
        self.__setitem__(key, "")

    def keys(self) -> list[str]:
        return self.kvstore.keys()

    def __len__(self) -> int:
        return len(self.keys())

    def __contains__(self, key: str) -> bool:
        return key in self.kvstore.keys()

    def __iter__(self) -> Iterator[str]:
        return iter(self.keys())


    def values(self) -> Iterator[str]:
        for k in self.keys():
            yield self.__getitem__(k)

    def items(self) -> Iterator[tuple[str, str]]:
        for k in self.keys():
            yield k, self.__getitem__(k)

    def __dict__(self) -> dict[str, str]:
        return dict(self.items())

    def __str__(self) -> str:
        return str(self.__dict__())

    def __repr__(self) -> str:
        return f"{self.__class__.__name__}(keys:[{', '.join(map(lambda s:f'"{s}"', self.keys()))}, ...])"

./conf/kvstore.json
[
  {
    "badger": "data/acceptor0",
    "rpc": "localhost:3000",
    "store": "localhost:4000"
  },
  {
    "badger": "data/acceptor1",
    "rpc": "localhost:3001",
    "store": "localhost:4001"
  },
  {
    "badger": "data/acceptor2",
    "rpc": "localhost:3002",
    "store": "localhost:4002"
  }
]./README.md
# kvstore

implementation of distributed kvstore using paxos

paxos is easier to understand and prove. raft is unnecessarily complicated

[proof](https://github.com/khanh101/khanh101.github.io/blob/master/blog/pdf/paxos-algorithm.pdf)

[pkg.go.dev](https://pkg.go.dev/github.com/khanh101/paxos)

## EXAMPLE

cluster is online if and only if a quorum is online

```bash
go run main.go conf/kvstore.json 0
go run main.go conf/kvstore.json 1
go run main.go conf/kvstore.json 2
```

```bash
# get all keys
curl http://localhost:4000/kvstore_keys -X GET
# get next write token
curl http://localhost:4000/kvstore_next -X GET
# write 
curl http://localhost:4000/kvstore/<key>?token=<token> -X PUT -d "<value>"
# read
curl http://localhost:4000/kvstore/<key> -X GET
# delete = write empty
curl http://localhost:4000/kvstore/<key>?token=<token> -X PUT -d ""
```


do you have any comment on this?
